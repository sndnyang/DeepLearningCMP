{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these packages are maybe useful\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU environment variables\n",
    "\n",
    "In notebook, maybe use %env will be a better solution, but not a general one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = \"1\"\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'          # for TensorFlow, which version?\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import code\n",
    "\n",
    "%load filename\n",
    "\n",
    "%%writefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from ExpUtils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also can load from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Playground')\n",
    "    parser.add_argument('--dataset', type=str, default='cifar10', help='cifar10, svhn (default: cifar10)')\n",
    "    parser.add_argument('--data-dir', type=str, default='./dataset', help='default: ./dataset')\n",
    "    parser.add_argument('--trainer', type=str, default='ce', help='ae, be, ce, de (default: ce)')\n",
    "    parser.add_argument('--size', type=int, default=1000, help='size of training data set(default: )')\n",
    "    parser.add_argument('--arch', type=str, default='CNN', help='MLP, CNN, ResNet, VGG')\n",
    "    parser.add_argument('--num-epochs', type=int, default=100, metavar='N', help='number of epochs (default: 100)')\n",
    "    \n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='N', help='random seed (default: 1)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False, help='disables CUDA training')\n",
    "    parser.add_argument('--gpu-id', type=str, default=\"\", metavar='N', help='gpu id list (default: auto select)')\n",
    "    parser.add_argument('--log-interval', type=int, default=1, metavar='N', help='iterations to wait before logging status, (default: 1)')\n",
    "    parser.add_argument('--batch-size', type=int, default=32, help='batch size of training data set (default: 32)')\n",
    "    \n",
    "    parser.add_argument('--lr', type=float, default=0.001, help='learning rate (default: 0.001)')\n",
    "    parser.add_argument('--lr-decay', type=float, default=0.95, help='learning rate decay (default: 0.95)')\n",
    "    parser.add_argument('--epoch-decay-start', type=float, default=80, help='start to decay learning rate (default: 80)')    \n",
    "    parser.add_argument('--affine', action='store_true', default=False, help='batch norm affine configuration')\n",
    "    \n",
    "    parser.add_argument('--drop', type=float, default=0.5, help='dropout rate, (default: 0.5)')\n",
    "    parser.add_argument('--log-dir', type=str, default='', metavar='S', help='tensorboard directory, (default: an absolute path)')\n",
    "    parser.add_argument('--log-arg', type=str, default='', metavar='S', help='show the arguments in directory name')\n",
    "    parser.add_argument('--debug', action='store_true', default=False, help='compare log side by side')\n",
    "    parser.add_argument('--vis', action='store_true', default=False, help='visual by tensor board')\n",
    "    parser.add_argument('-r', '--resume', type=str, default='', metavar='S', help='resume from pth file')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.dir_path = None\n",
    "\n",
    "    if args.gpu_id == \"\":\n",
    "        args.gpu_id = auto_select_gpu()\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu_id\n",
    "\n",
    "    if not args.log_arg:\n",
    "        args.log_arg = \"trainer-size-lr\"\n",
    "\n",
    "    if args.vis:\n",
    "        # use some parameters, pid and running time to mark the process\n",
    "        args_dict = vars(args)\n",
    "        run_time = time.strftime('%d%H%M', time.localtime(time.time()))\n",
    "        exp_marker = \"-\".join(\"%s=%s\" % (e, str(args_dict.get(e, \"None\"))) for e in args.log_arg.split(\"-\"))\n",
    "        exp_marker = \"NameABC/%s/%s_%d_%s\" % (args.dataset, exp_marker, os.getpid(), run_time)\n",
    "        base_dir = os.path.join(os.environ['HOME'], 'project/runs') if not args.log_dir else args.log_dir\n",
    "        dir_path = os.path.join(base_dir, exp_marker)\n",
    "        args.dir_path = dir_path\n",
    "        set_file_logger(logger, args)\n",
    "        args.writer = SummaryWriter(log_dir=dir_path)\n",
    "    wlog(\"args in this experiment:\\n%s\" % '\\n'.join(str(e) for e in sorted(vars(args).items())))\n",
    "\n",
    "    args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    args.device = device\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "    return args, kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_set, test_set, ..., args):    \n",
    "    arch = getattr(CNN, args.arch)\n",
    "    model = arch(args)\n",
    "    \n",
    "    if args.debug:\n",
    "        # for pytorch, or weight initialization in the model\n",
    "        # weights init is based on numpy, so only need np.random.seed()\n",
    "        np.random.seed(args.seed)\n",
    "        model.apply(weights_init_uniform)\n",
    "        \n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    # use linear lr decay or some other schedulers\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=args.lr_decay)\n",
    "    start_epoch = 0\n",
    "    if args.resume:\n",
    "        # resume example\n",
    "        checkpoint = load_checkpoint_by_marker(args, exp_marker)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(args.device)\n",
    "    model = model.to(args.device)\n",
    "    \n",
    "    for epoch/iteration in range(total_steps):\n",
    "        images, labels = train_set\n",
    "        \n",
    "        # loss = ...\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch/iteration % args.log_interval == 0:\n",
    "            n_err, test_loss = evaluate_classifier(model, test_loader, args.device)\n",
    "            acc = 1 - n_err / len(test_set)\n",
    "            print(\"Epoch %d, test acc: %.5f\" % (epoch, acc))\n",
    "            if args.vis:\n",
    "                if epoch % 5 == 0:\n",
    "                    # save the last model\n",
    "                    torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': test_loss, 'acc': acc},\n",
    "                               \"%s/%s.pth\" % (args.dir_path, \"model\"))\n",
    "                    if epoch % 50 == 0:\n",
    "                        # save the milestons\n",
    "                        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': test_loss, 'acc': acc},\n",
    "                                   \"%s/model_%d.pth\" % (args.dir_path, epoch))\n",
    "                        \n",
    "                args.writer.add_scalar(\"Train/total_loss\", total_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args, kwargs = parse_args()\n",
    "    set_framework_seed(args.seed, args.debug)  \n",
    "    train_set, test_set = load_dataset(args.data_dir, valid=False, dataset_seed=args.seed)\n",
    "    wlog(\"size of dataset\".format(train_set.size()))\n",
    "    train(train_set, test_set, ..., args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
